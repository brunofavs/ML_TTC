\subsection{Model selection and training setup}
\label{sec:model_selection}
To select the models, we prioritized the availability of source code and 
pre-trained weights. The PyTorch Vision framework currently provides three 
models for semantic segmentation: DeepLabV3~\cite{DeepLabV3}, FCN~\cite{fcn}, 
and LRASPP~\cite{LRASPP}. Among these, we selected DeepLabV3, as the authors 
reported the best results.

In addition to the PyTorch models, we sought a simple and well-established model 
to serve as a baseline. For this purpose, we chose U-Net~\cite{unet}.

Since this problem involves only one class of interest—the checkerboard—with all 
other pixels considered background, it can be framed as a binary classification 
task at the pixel level. Consequently, we selected a loss function designed for 
binary classification: binary cross-entropy loss.

For optimization, we experimented with the Adam optimizer due to its fast 
convergence and adaptive learning rates. Additionally, we evaluated Adam with 
Weight Decay to mitigate potential overfitting.

For batch size, we used the maximum value that the GPU could accommodate.

We attempted to implement an automatic stopping criterion based on loss and 
accuracy. Training would stop if the loss did not decrease for five consecutive 
epochs or if the accuracy did not improve within the same period. However, this 
approach led to premature stopping due to the instability of training, as 
discussed in the next section. Consequently, we opted to train for a fixed 200 
epochs and retain the model with the highest accuracy.